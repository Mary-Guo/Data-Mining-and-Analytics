{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[{"file_id":"1rD8HOK9O7SSv_MsjO9nqhTUPcxfOduYH","timestamp":1667170161651},{"file_id":"1vHXYiSlQntcoXmvcJkRae8OWpkUDDo_X","timestamp":1666750244936}]}},"cells":[{"cell_type":"code","metadata":{"id":"IDlU-kLCKDVZ"},"source":["NAME = \"Mary Guo\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kW9zL4V6KDVc"},"source":["---"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"9a0ec075584699a44c46933457b0a8ba","grade":false,"grade_id":"cell-a910b376742d04c0","locked":true,"schema_version":1,"solution":false},"id":"ECD5r2hFKDVd"},"source":["# Lab 6: Skip Gram\n","\n","**Please read the following instructions very carefully**\n","\n","## Working on the assignment / FAQs\n","- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across students and coding environments) \n","- The type of question and the points they carry are indicated in each question cell\n","- To avoid any ambiguity, each question also specifies what *value* must be set. Note that these are dummy values and not the answers\n","- If an autograded question has multiple answers (due to differences in handling NaNs, zeros etc.), all answers will be considered.\n","- You can delete the `raise NotImplementedError()`\n","- **Submitting the assignment** : Download the '.ipynb' file from Colab and upload it to bcourses. Do not delete any outputs from cells before submitting.\n","- That's about it. Happy coding!\n","\n","\n","Available software:\n"," - Python's Gensim module: https://radimrehurek.com/gensim/ (install using pip)\n","\n","_Note: The most important hyper parameters of skip-gram/CBOW are vector size and windows size_\n"]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"a09a0bf3042da711c4bf843e9b4a4189","grade":false,"grade_id":"cell-bf780e597c0216c8","locked":true,"schema_version":1,"solution":false},"id":"Vsocwry-KDVe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667405381493,"user_tz":420,"elapsed":4982,"user":{"displayName":"Mary Guo","userId":"16590739356738127017"}},"outputId":"fe27ebd1-8999-43a2-9088-519747baa7f6"},"source":["!pip install gensim\n","import pandas as pd\n","import numpy as np \n","import gensim"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n"]}]},{"cell_type":"code","source":["import gensim.downloader as api\n","\n","model = api.load('word2vec-google-news-300') # this step might take ~10-15 minutes"],"metadata":{"id":"TIcyAqlk6Qpy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"47031c66b74746d23ccc5e8369446a4b","grade":false,"grade_id":"cell-3f89500615a0096f","locked":true,"schema_version":1,"solution":false},"id":"ZF74G9bDKDVh"},"source":["### **Q1 (1 point)** \n","Find the cosine similarity between the following word pairs\n","\n","- (France, England)\n","- (smaller, bigger)\n","- (England, London)\n","- (France, Rocket)\n","- (big, bigger)"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"4d52dda406c3d8cd5e37d29755f0fb12","grade":false,"grade_id":"cell-fbbe575f8f5a6368","locked":false,"schema_version":1,"solution":true},"id":"SZD5ZaMvKDVk"},"source":["#Replace 0 with the code / value; Do not delete this cell\n","similarity_pair1 = model.similarity('France', 'England')\n","similarity_pair2 = model.similarity('smaller', 'bigger')\n","similarity_pair3 = model.similarity('England', 'London')\n","similarity_pair4 = model.similarity('France', 'Rocket')\n","similarity_pair5 = model.similarity('big', 'bigger')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"569aa8b664a41d901bf7b0a5e23e9930","grade":true,"grade_id":"cell-929d59ed5d67f618","locked":true,"points":1,"schema_version":1,"solution":false},"id":"tFUPLSK7KDVp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667405592574,"user_tz":420,"elapsed":194,"user":{"displayName":"Mary Guo","userId":"16590739356738127017"}},"outputId":"3053f07b-548d-4445-c9fc-d1cdadf14ee2"},"source":["#This is an autograded cell, do not edit/delete\n","print(similarity_pair1, similarity_pair2, similarity_pair3, similarity_pair4, similarity_pair5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.39804944 0.7302272 0.43992856 0.07114174 0.68423855\n"]}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"a7f270405ddf9ecbffde36e6c096b818","grade":false,"grade_id":"cell-ccd6618b4fac3715","locked":true,"schema_version":1,"solution":false},"id":"ZcqpWCjJKDVs"},"source":["### **Q2 (1 point)** \n","Write an expression to extract the vector representations of the words: \n","\n","- France\n","- England\n","- smaller\n","- bigger\n","- rocket\n","- big\n","\n","Get only the first 5 elements for each vector representation."]},{"cell_type":"code","source":["#Replace 0 with the code / value to get the first 5 elements of each vector; Do not delete this cell\n","vector_1 = model['France'][:5]\n","vector_2 = model['England'][:5]\n","vector_3 = model['smaller'][:5]\n","vector_4 = model['bigger'][:5]\n","vector_5 = model['rocket'][:5]\n","vector_6 = model['big'][:5]"],"metadata":{"id":"ElgK5QLuGi6S"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"401940f859774b3c1ec48338fa15682e","grade":true,"grade_id":"cell-6f34229370fa873f","locked":true,"points":1,"schema_version":1,"solution":false},"id":"Hkj2ROGTKDVv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667359497105,"user_tz":420,"elapsed":162,"user":{"displayName":"Mary Guo","userId":"16590739356738127017"}},"outputId":"d5ab09f2-cb55-46a9-a3cf-ecde5618fccf"},"source":["#This is an autograded cell, do not edit/delete\n","print(vector_1)\n","print(vector_2)\n","print(vector_3)\n","print(vector_4)\n","print(vector_5)\n","print(vector_6)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.04858398 0.07861328 0.32421875 0.03491211 0.07714844]\n","[-0.19824219  0.11523438  0.0625     -0.05834961  0.2265625 ]\n","[-0.05004883  0.03417969 -0.0703125   0.17578125  0.00689697]\n","[-0.06542969 -0.09521484 -0.06225586  0.16210938  0.01989746]\n","[-0.03198242  0.27148438 -0.2890625  -0.15429688  0.16894531]\n","[ 0.11132812  0.10595703 -0.07373047  0.18847656  0.07666016]\n"]}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"ac8b42811c924e7988f17b9dbd3f71ef","grade":false,"grade_id":"cell-4ad44071d3785409","locked":true,"schema_version":1,"solution":false},"id":"2UBnMwiXKDVy"},"source":["### **Q3 (1 point)** \n","Find the euclidean distances between the word pairs : \n","\n","- (France, England)\n","- (smaller, bigger)\n","- (England, London)\n","- (France, Rocket)\n","- (big, bigger)\n"]},{"cell_type":"code","source":["#Replace 0 with the code / value; Do not delete this cell\n","eu_dist1 = np.sqrt(np.sum((model['France'] - model['England'])**2))\n","eu_dist2 = np.sqrt(np.sum((model['smaller'] - model['bigger'])**2))\n","eu_dist3 = np.sqrt(np.sum((model['England'] - model['London'])**2))\n","eu_dist4 = np.sqrt(np.sum((model['France'] - model['Rocket'])**2))\n","eu_dist5 = np.sqrt(np.sum((model['big'] - model['bigger'])**2))"],"metadata":{"id":"JYUdXmCOMg45"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"17796eb5de342e8f8e841aa137a2c41c","grade":true,"grade_id":"cell-15ffa50b82de21ad","locked":true,"points":1,"schema_version":1,"solution":false},"id":"HsSg0l2UKDV6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667367914416,"user_tz":420,"elapsed":153,"user":{"displayName":"Mary Guo","userId":"16590739356738127017"}},"outputId":"35df9757-31be-4fd5-99a7-bf32ed35954e"},"source":["#This is an autograded cell, do not edit / delete\n","print(eu_dist1)\n","print(eu_dist2)\n","print(eu_dist3)\n","print(eu_dist4)\n","print(eu_dist5)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.0151067\n","1.8618743\n","2.8752837\n","3.892071\n","1.9586496\n"]}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"afc0e843c7545e2df83448feda9f28f5","grade":false,"grade_id":"cell-7cd8b9b67386376d","locked":true,"schema_version":1,"solution":false},"id":"XvO2iU7QKDWA"},"source":["### **Q4 (1 point)**\n","Time to dabble with the power of Word2Vec. Find the 2 closest words  for the following conditions:  \n","- (King - Man + Queen)\n","- (bigger - big + small)\n","- (waiting - wait + run)\n","- (Texas + Milwaukee â€“ Wisconsin)\n","\n","Note: If your kernel crashes due to low memory and restarts, reload the model from the top and try running this part again."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"50ef096feb166865434fe2fca3d41f99","grade":false,"grade_id":"cell-b72201968c5fd1ec","locked":false,"schema_version":1,"solution":true},"id":"jCxWmA1eKDWB"},"source":["#Replace 0 with the code / value; Do not delete this cell\n","closest1 = model.most_similar(positive=['Queen', 'King'], negative=['Man'])[:2]\n","closest2 = model.most_similar(positive=['bigger', 'small'], negative=['big'])[:2]\n","closest3 = model.most_similar(positive=['waiting', 'run'], negative=['wait'])[:2]\n","closest4 = model.most_similar(positive=['Texas', 'Milwaukee'], negative=['Wisconsin'])[:2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"f9c5ff502264f29d2632c6387f92686a","grade":true,"grade_id":"cell-b69718ab0e1470bc","locked":true,"points":1,"schema_version":1,"solution":false},"id":"io9elfD8KDWE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667367922343,"user_tz":420,"elapsed":9,"user":{"displayName":"Mary Guo","userId":"16590739356738127017"}},"outputId":"0ef998b8-9e2d-4258-8bd7-404fe1f92a99"},"source":["#This is an autograded cell, do not edit/delete\n","print(closest1)\n","print(closest2)\n","print(closest3)\n","print(closest4)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Queen_Elizabeth', 0.5257916450500488), ('monarch', 0.5004087090492249)]\n","[('larger', 0.7402471899986267), ('smaller', 0.732999324798584)]\n","[('running', 0.5654535889625549), ('runs', 0.49640005826950073)]\n","[('Houston', 0.7767744064331055), ('Fort_Worth', 0.7270511388778687)]\n"]}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"6432058d78f4fa52224c48a3b3e71d0d","grade":false,"grade_id":"cell-73dca0e2072fef91","locked":true,"schema_version":1,"solution":false},"id":"erUu4u71KDWJ"},"source":["### **Q5 (3 points)**\n","Using the vectors for the words in the Google News dataset, apply K-means clustering (K=2) and find the top 5 most representative words/phrases of each cluster.\n","\n","*Note: Since there are ~3Mil words in the vocabulary, you can downsample it to 25k randomly selected words*  \\\\\n","*Hint: The \"similar_by_vector\" method might be useful*\n","\n","**Do not delete the below cell**"]},{"cell_type":"code","source":["# Replace 0 with the code / value; Do not delete this cell\n","# YOUR CODE HERE\n","import random\n","from sklearn.cluster import KMeans\n","d = model.wv.vocab\n","keys = random.sample(d.keys(), 25000)\n","sample_d = {k: d[k] for k in keys}\n","word_list = list(sample_d.keys())\n","dic = {}\n","for i in word_list:\n","  dic[i] = model[i]\n","df = pd.DataFrame.from_dict(dic).T\n","kmeans = KMeans(n_clusters=2, random_state=42)\n","kmeans.fit(df)\n","df['Cluster'] = kmeans.labels_\n","\n","most_rep_cluster1 = model.similar_by_vector(kmeans.cluster_centers_[0], topn= 5)\n","most_rep_cluster2 = model.similar_by_vector(kmeans.cluster_centers_[1], topn= 5)"],"metadata":{"id":"iqTEPYr_YuRu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667405407358,"user_tz":420,"elapsed":20052,"user":{"displayName":"Mary Guo","userId":"16590739356738127017"}},"outputId":"ab37b101-9b51-46f6-e2b2-1d6aa331627e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n"]}]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"7ecef46689f11d4d0a6fed72e049235f","grade":true,"grade_id":"cell-80b177848b8b0212","locked":false,"points":3,"schema_version":1,"solution":true},"id":"M3jN02fOKDWK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667405415322,"user_tz":420,"elapsed":202,"user":{"displayName":"Mary Guo","userId":"16590739356738127017"}},"outputId":"f4444b17-c225-4026-e194-374d87553739"},"source":["#This is an autograded cell, do not edit/delete\n","print(most_rep_cluster1)\n","print(most_rep_cluster2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Emil_Protalinski_Published', 0.9207786321640015), ('By_HuDie_####-##-##', 0.9197227954864502), ('By_QianMian_####-##-##', 0.9189141988754272), ('BY_GEOFF_KOHL', 0.9173696041107178), ('By_XiaoBing_####-##-##', 0.9158244729042053)]\n","[('http_dol##.net_index###.html_http', 0.9156659841537476), ('dol##.net_index####.html_http_dol##.net', 0.9051403999328613), ('index###.html_http_dol##.net_index###.html', 0.9039607048034668), ('Deltagen_undertakes', 0.9031954407691956), ('By_TRICIA_SCRUGGS', 0.8980017900466919)]\n"]}]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"0467b27a0f59504cbb62b851a002386f","grade":false,"grade_id":"cell-5b2a5e8ff6c74323","locked":true,"schema_version":1,"solution":false},"id":"rmdtLoHkKDWR"},"source":["### **Q6 (1 point)**\n","What loss function does the skipgram model use and briefly describe what this function is minimizing.\n","\n","**Do not delete the below cell**"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"774aef2c5bf8ef9d92e3489d1cd80390","grade":true,"grade_id":"cell-90cc4b2c0ae8e2c2","locked":false,"points":1,"schema_version":1,"solution":true},"id":"SyOASYXOKDWS"},"source":["# YOUR CODE HERE\n","#The skipgram model use categorical cross-entropy as loss function. \n","#The function is minimizing the scores that\n","#measures how far the predicted values to the real values.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"c14f6069f64cc86ab6e384d28df270d8","grade":false,"grade_id":"cell-74a177caaabb5009","locked":true,"schema_version":1,"solution":false},"id":"dbpuJx9CKDWV"},"source":["### **Bonus Question (1 point)** \n","Find at least 2 interesting word vec combinations like the ones given in Q4\n","\n","**Do not delete the below cell**"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"c2d42b5327f4b020c7e1706506dd5ce9","grade":true,"grade_id":"cell-7351297993d72e83","locked":false,"points":1,"schema_version":1,"solution":true},"id":"pQM8C_T7KDWW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667370195128,"user_tz":420,"elapsed":894,"user":{"displayName":"Mary Guo","userId":"16590739356738127017"}},"outputId":"f72d2f3d-95b8-45d8-e2f0-3b9e7cf0a657"},"source":["# YOUR CODE HERE\n","first = model.most_similar(positive=['older', 'young'], negative=['old'])\n","second = model.most_similar(positive=['Actor', 'Actress'], negative=['Man'])\n","first, second"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([('younger', 0.6766281127929688),\n","  ('Older', 0.5549312829971313),\n","  ('Younger', 0.5469749569892883),\n","  ('Elena_Losina_co', 0.4923054277896881),\n","  ('By_Yoon_Ja', 0.4731638431549072),\n","  ('advantaged_backgrounds', 0.4675189256668091),\n","  ('By_Soh_Ji', 0.46451276540756226),\n","  ('socially_disadvantaged_backgrounds', 0.4569123089313507),\n","  ('Nonwhite', 0.4566728472709656),\n","  ('generation_Xers', 0.4522029757499695)],\n"," [('actress', 0.6319977641105652),\n","  ('Today_Birthdays_Actress', 0.5881161689758301),\n","  ('actor', 0.5873674154281616),\n","  ('Gaby_Hoffman', 0.5621989965438843),\n","  ('Sue_Ane_Langdon', 0.5601475238800049),\n","  ('ACTOR', 0.5565818548202515),\n","  ('ACTRESS', 0.5509848594665527),\n","  ('LR_Actors', 0.546001672744751),\n","  ('Stefanie_Powers', 0.5432376861572266),\n","  ('Comedienne', 0.5356159210205078)])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":[],"metadata":{"id":"TyK9I4sY3vvf"},"execution_count":null,"outputs":[]}]}